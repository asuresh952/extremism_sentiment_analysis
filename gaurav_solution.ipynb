{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ff4818",
   "metadata": {},
   "source": [
    " # Social Media Extremism Detection Using a Hybrid RoBERTa + Calibrated SVM Ensemble\n",
    "\n",
    " This notebook trains and explains a hybrid ensemble model to detect extremist\n",
    " content in social media text. The workflow:\n",
    "\n",
    " 1. **Data loading & label encoding**\n",
    " 2. **Feature engineering (SVM)**: TF–IDF n-grams\n",
    " 3. **Model training**:\n",
    "    - Model A: **Calibrated LinearSVC** on TF–IDF\n",
    "    - Model B: **RoBERTa-base** fine-tuning with **3-seed bagging**\n",
    "    - Hybrid Blend: **0.6 RoBERTa + 0.4 SVM**\n",
    " 4. **Evaluation**: accuracy, F1, ROC/PR curves, calibration metrics\n",
    " 5. **Explainability**:\n",
    "    - SHAP for the SVM (global & local)\n",
    "    - Token-level SHAP for RoBERTa (local, lightweight)\n",
    " 6. **Quality control**: flagging potential label issues for manual review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52241234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 0. Imports & Global Config\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    log_loss, brier_score_loss,\n",
    ")\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "import shap\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_SEED = 30\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "DATA_PATH = \"extremism_data_final.csv\"\n",
    "\n",
    "# Model config (matches “Gaurav approach”)\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "SEEDS = [42, 2024, 999]  # bagging seeds\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "LR = 2e-5\n",
    "\n",
    "# TF-IDF (matches approach)\n",
    "TFIDF_NGRAM_RANGE = (1, 3)\n",
    "TFIDF_MIN_DF = 2\n",
    "\n",
    "# Ensemble settings\n",
    "W_ROBERTA = 0.6\n",
    "W_SVM = 0.4\n",
    "VAL_THRESHOLD = 0.5\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59526cb0",
   "metadata": {},
   "source": [
    " ## 1. Data Loading and Label Encoding\n",
    "\n",
    " In this section, we:\n",
    " - Load the raw dataset from `extremism_data_final.csv`\n",
    " - Preserve the original row index (`row_id`)\n",
    " - Encode labels into a binary target\n",
    " - Run a quick exploratory analysis on label distribution and text lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f885a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (2777, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Message</th>\n",
       "      <th>Extremism_Label</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sixth forms should burn to the ground</td>\n",
       "      <td>EXTREMIST</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whatever should burn benders to the ground</td>\n",
       "      <td>EXTREMIST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>factories should burn to the ground</td>\n",
       "      <td>EXTREMIST</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>halal factories should burn to the ground</td>\n",
       "      <td>EXTREMIST</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nhs should burn to the ground</td>\n",
       "      <td>EXTREMIST</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Original_Message Extremism_Label  row_id\n",
       "0       sixth forms should burn to the ground       EXTREMIST       0\n",
       "1  whatever should burn benders to the ground       EXTREMIST       1\n",
       "2         factories should burn to the ground       EXTREMIST       2\n",
       "3   halal factories should burn to the ground       EXTREMIST       3\n",
       "4               nhs should burn to the ground       EXTREMIST       4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load the Dataset\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Keep track of original row index so we can retrieve later\n",
    "df[\"row_id\"] = df.index\n",
    "\n",
    "print(\"Dataset loaded. Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9eb1f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "Extremism_Label\n",
      "NON_EXTREMIST    1454\n",
      "EXTREMIST        1323\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution (proportions):\n",
      "Extremism_Label\n",
      "NON_EXTREMIST    0.523587\n",
      "EXTREMIST        0.476413\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Encode labels and basic EDA\n",
    "\n",
    "label_map = {\"EXTREMIST\": 1, \"NON_EXTREMIST\": 0}\n",
    "df[\"Binary_Label\"] = df[\"Extremism_Label\"].map(label_map).astype(np.int64)\n",
    "y = df[\"Binary_Label\"].values\n",
    "\n",
    "print(\"Label distribution:\")\n",
    "print(df[\"Extremism_Label\"].value_counts())\n",
    "print(\"\\nLabel distribution (proportions):\")\n",
    "print(df[\"Extremism_Label\"].value_counts(normalize=True))\n",
    "\n",
    "# Quick text length distribution\n",
    "texts_all = df[\"Original_Message\"].fillna(\"\").astype(str)\n",
    "text_lengths = texts_all.str.len()\n",
    "\n",
    "plt.hist(text_lengths, bins=30)\n",
    "plt.title(\"Distribution of Text Lengths\")\n",
    "plt.xlabel(\"Number of characters in Original_Message\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e1a05",
   "metadata": {},
   "source": [
    " ## 2. Feature Engineering (SVM): TF–IDF n-grams\n",
    "\n",
    " We construct a sparse representation of each message by:\n",
    " - Fitting a TF–IDF vectorizer on 1–3 gram tokens\n",
    " - Producing sparse feature matrices for train/validation\n",
    " - Building an aligned `feature_names` list for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7a7000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TF-IDF features: 14057\n"
     ]
    }
   ],
   "source": [
    "# 3. Fit TF-IDF on the corpus\n",
    "\n",
    "texts = texts_all.tolist()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=TFIDF_NGRAM_RANGE,\n",
    "    min_df=TFIDF_MIN_DF,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "tfidf_vectorizer.fit(texts)\n",
    "\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out().tolist()\n",
    "print(\"Number of TF-IDF features:\", len(tfidf_feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90641666",
   "metadata": {},
   "source": [
    " ## 3. Train/Validation Split\n",
    "\n",
    " We:\n",
    " - Create a stratified train/validation split on the labeled dataset\n",
    " - Keep the raw text around for interpretability\n",
    " - Prepare both TF–IDF matrices (for SVM) and tokenized datasets (for RoBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c871af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2221 Val size: 556\n",
      "Example train text: on me i am about to have this bitch blasted i had enough of this bullshit i hate crying because i have to hold in the urge to kill an old vagina\n"
     ]
    }
   ],
   "source": [
    "# 4. Train/validation split (stratified)\n",
    "\n",
    "X_text_train, X_text_val, y_train, y_val, idx_train, idx_val = train_test_split(\n",
    "    texts_all.values,\n",
    "    y,\n",
    "    df[\"row_id\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_text_train), \"Val size:\", len(X_text_val))\n",
    "print(\"Example train text:\", X_text_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04da2974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tfidf shape: (2221, 14057)\n",
      "X_val_tfidf shape:   (556, 14057)\n"
     ]
    }
   ],
   "source": [
    "# 4b. TF-IDF matrices for SVM\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_text_train)\n",
    "X_val_tfidf   = tfidf_vectorizer.transform(X_text_val)\n",
    "\n",
    "print(\"X_train_tfidf shape:\", X_train_tfidf.shape)\n",
    "print(\"X_val_tfidf shape:  \", X_val_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf7e20",
   "metadata": {},
   "source": [
    " ## 4. Model A — Calibrated LinearSVC (TF–IDF)\n",
    "\n",
    " We train a linear SVM on TF–IDF features and calibrate it to produce\n",
    " well-formed probabilities using `CalibratedClassifierCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3c5d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Validation Accuracy: 0.8345323741007195\n",
      "SVM Validation F1 (macro): 0.8343587684416409\n"
     ]
    }
   ],
   "source": [
    "# 5. Train calibrated SVM and get validation probabilities\n",
    "\n",
    "base_svc = LinearSVC(class_weight=\"balanced\", C=1.0, random_state=42, dual=False)\n",
    "svm = CalibratedClassifierCV(base_svc, cv=5)\n",
    "\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "svm_val_probs = svm.predict_proba(X_val_tfidf)[:, 1]\n",
    "svm_val_pred  = (svm_val_probs >= VAL_THRESHOLD).astype(int)\n",
    "\n",
    "print(\"SVM Validation Accuracy:\", accuracy_score(y_val, svm_val_pred))\n",
    "print(\"SVM Validation F1 (macro):\", f1_score(y_val, svm_val_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1086c5",
   "metadata": {},
   "source": [
    " ## 5. Model B — RoBERTa-base Fine-tuning with 3-Seed Bagging\n",
    "\n",
    " We:\n",
    " - Tokenize train/validation texts\n",
    " - Fine-tune RoBERTa for 3 epochs\n",
    " - Repeat across 3 seeds and average validation probabilities\n",
    "\n",
    " We also capture training logs (loss curves) from one seed to visualize training dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a813aa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5860e486bcd349fcbbde772d151a139b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a75450e823646eea3e6fa79b08f7799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/556 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 2221\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 556\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 6. Tokenization + Dataset preparation\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, max_length=128)\n",
    "\n",
    "train_ds = Dataset.from_dict({\"text\": X_text_train.tolist(), \"labels\": y_train.tolist()})\n",
    "val_ds   = Dataset.from_dict({\"text\": X_text_val.tolist(),   \"labels\": y_val.tolist()})\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "val_ds   = val_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "train_ds.set_format(\"torch\")\n",
    "val_ds.set_format(\"torch\")\n",
    "\n",
    "print(train_ds)\n",
    "print(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0566878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RoBERTa seed 42 (1/3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/88/x42msnrd1t33_gxpn60flc100000gn/T/ipykernel_63070/775707463.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='417' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 41/417 08:57 < 1:26:20, 0.07 it/s, Epoch 0.29/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 5.27 GB, other allocations: 3.79 GB, max allowed: 9.07 GB). Tried to allocate 147.26 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     12\u001b[39m args = TrainingArguments(\n\u001b[32m     13\u001b[39m     output_dir=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./checkpoints_seed_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     learning_rate=LR,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     data_seed=seed,\n\u001b[32m     27\u001b[39m )\n\u001b[32m     29\u001b[39m trainer = Trainer(\n\u001b[32m     30\u001b[39m     model=model,\n\u001b[32m     31\u001b[39m     args=args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     data_collator=data_collator,\n\u001b[32m     36\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# save log history for plots (first seed only, to mirror the “curves” section)\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m log_history_for_plots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/extremism_sentiment_analysis/.venv/lib/python3.12/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/extremism_sentiment_analysis/.venv/lib/python3.12/site-packages/transformers/trainer.py:2740\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2737\u001b[39m     context = implicit_replication\n\u001b[32m   2739\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2740\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2742\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_optimizer_step(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m   2744\u001b[39m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/extremism_sentiment_analysis/.venv/lib/python3.12/site-packages/accelerate/optimizer.py:179\u001b[39m, in \u001b[36mAcceleratedOptimizer.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    177\u001b[39m         \u001b[38;5;28mself\u001b[39m._accelerate_step_called = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator_state.distributed_type == DistributedType.XLA:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.gradient_state.is_xla_gradients_synced = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/extremism_sentiment_analysis/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:75\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m instance._step_count += \u001b[32m1\u001b[39m\n\u001b[32m     74\u001b[39m wrapped = func.\u001b[34m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/extremism_sentiment_analysis/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:385\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    382\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    383\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/extremism_sentiment_analysis/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:76\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m'\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     75\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/extremism_sentiment_analysis/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:187\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    174\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    176\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    177\u001b[39m         group,\n\u001b[32m    178\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m         state_steps,\n\u001b[32m    185\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/extremism_sentiment_analysis/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:339\u001b[39m, in \u001b[36madamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    337\u001b[39m     func = _single_tensor_adamw\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/extremism_sentiment_analysis/.venv/lib/python3.12/site-packages/torch/optim/adamw.py:470\u001b[39m, in \u001b[36m_single_tensor_adamw\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[39m\n\u001b[32m    468\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    469\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m         denom = (\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / bias_correction2_sqrt).add_(eps)\n\u001b[32m    472\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    474\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 5.27 GB, other allocations: 3.79 GB, max allowed: 9.07 GB). Tried to allocate 147.26 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 7. RoBERTa training loop (3 seeds) + probability averaging\n",
    "\n",
    "all_seed_val_probs = []\n",
    "log_history_for_plots = None  # store from first seed for training dynamics plots\n",
    "\n",
    "for j, seed in enumerate(SEEDS):\n",
    "    print(f\"\\nTraining RoBERTa seed {seed} ({j+1}/{len(SEEDS)})...\")\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2).to(DEVICE)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"./checkpoints_seed_{seed}\",\n",
    "        learning_rate=LR,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",  # Changed from evaluation_strategy\n",
    "        save_strategy=\"no\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        seed=seed,\n",
    "        data_seed=seed,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # save log history for plots (first seed only, to mirror the “curves” section)\n",
    "    if log_history_for_plots is None:\n",
    "        log_history_for_plots = trainer.state.log_history\n",
    "\n",
    "    # Predict on validation\n",
    "    preds = trainer.predict(val_ds).predictions\n",
    "    probs = torch.softmax(torch.tensor(preds), dim=1)[:, 1].cpu().numpy()\n",
    "    all_seed_val_probs.append(probs)\n",
    "\n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "roberta_val_probs = np.mean(all_seed_val_probs, axis=0)\n",
    "roberta_val_pred  = (roberta_val_probs >= VAL_THRESHOLD).astype(int)\n",
    "\n",
    "print(\"\\nRoBERTa (bagged) Validation Accuracy:\", accuracy_score(y_val, roberta_val_pred))\n",
    "print(\"RoBERTa (bagged) Validation F1 (macro):\", f1_score(y_val, roberta_val_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33367c9",
   "metadata": {},
   "source": [
    " ## 6. Hybrid Blend (0.6 RoBERTa + 0.4 SVM)\n",
    "\n",
    " We combine the two probability estimates:\n",
    "\n",
    " \\[\n",
    " p_{\\text{ensemble}} = 0.6 \\cdot p_{\\text{RoBERTa}} + 0.4 \\cdot p_{\\text{SVM}}\n",
    " \\]\n",
    "\n",
    " Then we threshold at 0.5 to produce predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1db450",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roberta_val_probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 8. Ensemble probabilities and predictions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m ensemble_val_probs = (W_ROBERTA * \u001b[43mroberta_val_probs\u001b[49m) + (W_SVM * svm_val_probs)\n\u001b[32m      4\u001b[39m ensemble_val_pred  = (ensemble_val_probs >= VAL_THRESHOLD).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      6\u001b[39m acc = accuracy_score(y_val, ensemble_val_pred)\n",
      "\u001b[31mNameError\u001b[39m: name 'roberta_val_probs' is not defined"
     ]
    }
   ],
   "source": [
    "# 8. Ensemble probabilities and predictions\n",
    "\n",
    "ensemble_val_probs = (W_ROBERTA * roberta_val_probs) + (W_SVM * svm_val_probs)\n",
    "ensemble_val_pred  = (ensemble_val_probs >= VAL_THRESHOLD).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_val, ensemble_val_pred)\n",
    "f1_macro = f1_score(y_val, ensemble_val_pred, average=\"macro\")\n",
    "f1_weighted = f1_score(y_val, ensemble_val_pred, average=\"weighted\")\n",
    "\n",
    "print(\"Ensemble metrics on validation set:\")\n",
    "print(f\"Accuracy:      {acc:.4f}\")\n",
    "print(f\"F1 (macro):    {f1_macro:.4f}\")\n",
    "print(f\"F1 (weighted): {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c64a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
